{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Objective function from Information Theory perspective*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Data loading from MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dataset\n",
    "import torchvision\n",
    "\n",
    "train_dataset = dataset.MNIST(root = './data', train = True, transform = transforms.ToTensor(), download = True )\n",
    "test_dataset = dataset.MNIST(root = './data', train = False, transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Define dataloaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 100\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Network model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as fun\n",
    "import torch.nn as nn\n",
    "class DeepNN(nn.Module):\n",
    "    def __init__(self, input_dim, nh1, nh2, nh3, nh4, nh5, output_dim):\n",
    "        super(DeepNN, self).__init__()\n",
    "        #hyperparameter setting \n",
    "        self.input_dim = input_dim\n",
    "        self.nh1, self.nh2, self.nh3, self.nh4, self.nh5, = nh1, nh2, nh3, nh4, nh5\n",
    "        self.output_dim = output_dim\n",
    "        #layer definition \n",
    "        self.input_layer = nn.Linear(self.input_dim, self.nh1)\n",
    "        self.hlayer1 = nn.Linear(self.nh1, self.nh2)\n",
    "        self.hlayer2 = nn.Linear(self.nh2, self.nh3)\n",
    "        self.hlayer3 = nn.Linear(self.nh3, self.nh4)\n",
    "        self.hlayer4 = nn.Linear(self.nh4, self.nh5)\n",
    "        self.output_layer = nn.Linear(self.nh5, self.output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #propogation of each layer\n",
    "        self.out1 = fun.relu(self.input_layer(x))\n",
    "        self.out2 = fun.relu(self.hlayer1(self.out1))\n",
    "        self.out3 = fun.relu(self.hlayer2(self.out2))\n",
    "        self.out4 = fun.relu(self.hlayer3(self.out3))\n",
    "        self.out5 = fun.relu(self.hlayer4(self.out4))\n",
    "        self.out6 = fun.relu(self.output_layer(self.out5))\n",
    "        return fun.log_softmax(self.out6, dim = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = DeepNN(784, 1000, 1200, 1100, 1000, 100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obj.cuda()          #if GPU available enable CUDA extension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Define Loss criterion and optimization method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "criterion = nn.CrossEntropyLoss\n",
    "optimizer = torch.optim.Adam(obj.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Train Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-de224f08d7f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mloss_monitor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch %d/%d Loss: %.5f'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_monitor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_monitor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_monitor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_monitor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" --------------------- \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "epochs = 2\n",
    "train_loss = []\n",
    "for epoch in range(epochs):\n",
    "    loss_monitor = []\n",
    "    for i,(images, labels) in enumerate(train_loader):\n",
    "        images = images.reshape(-1, 28*28)\n",
    "        optimizer.zero_grad()\n",
    "        pred = obj(images)\n",
    "        loss = fun.nll_loss(pred, labels)\n",
    "        #loss = criterion(pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 100 == 0:                              \n",
    "            loss_monitor.append(loss.item())\n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'%(epoch+1, epochs, i+1, len(train_dataset)//batch_size, loss.item()))\n",
    "    print('Epoch %d/%d Loss: %.5f'%(epoch+1,epochs,sum(loss_monitor)/len(loss_monitor)))\n",
    "    train_loss.append(sum(loss_monitor)/len(loss_monitor))\n",
    "    print(\" --------------------- \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "figure = plt.figure()\n",
    "plt.plot(range(epochs), train_loss, color = 'blue')\n",
    "plt.legend([train_loss], loc = 'upper right')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Training Loss')\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
