# HyperGraph based Information Theory approach for effective Pretraining

## Introduction

Deep Learning (DL) - an integral part of neural network guarantees higher accuracy and 
flexibility by learning to represent the world as nested hierarchy of Information, 
with each defined in relation to simpler ones. Powerful features of DL such as increase 
in robustness and performance of the model by increase in size of the data, learning 
high-level features from the data incrementally without feature engineering and end-to-end 
problem solving capability, make four among five researchers believe that the advent of 
DL makes life easier. Pre-training is widely adapted in DL as it helps in finding better 
starting point in loss topology for improved Empirical Risk Minimization. Particularly, 
Unsupervised Pretraining focuses on effective Information feature transforming and representing 
through layers, which reduce high time-consuming exploration phase of the Optimization algorithm. 
Recent works on understanding unfathomable concepts of DL and various algorithms to improve 
state-of-art methods through Information Theory based approach has proved very successful. 
In this work we propose a novel Information Theory based Hypergraph approach to pretrain the model,
which is very effecient.


