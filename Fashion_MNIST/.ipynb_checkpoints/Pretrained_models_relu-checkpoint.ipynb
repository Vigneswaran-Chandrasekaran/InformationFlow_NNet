{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras \n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"fashion-mnist_train.csv\")\n",
    "train_label = pd.DataFrame(train_data[[\"label\"]].copy(deep=False)) \n",
    "train_input = pd.DataFrame(train_data.drop(\"label\", 1, inplace=False))\n",
    "train_label = keras.utils.to_categorical(train_label)\n",
    "train_input = (train_input - train_input.mean(axis=0)) / train_input.std(axis=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Comparision with Weight Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(Dense(units=1024, input_dim=train_input.shape[1], activation=\"relu\"))\n",
    "#model.add(Dropout(0.30))\n",
    "model.add(Dense(units=200, activation=\"relu\"))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Dense(units=20, activation=\"relu\"))\n",
    "#model.add(Dropout(0.20))\n",
    "model.add(Dense(units=20, activation=\"relu\"))\n",
    "#model.add(Dropout(0.15))\n",
    "model.add(Dense(units=20, activation=\"relu\"))\n",
    "#model.add(Dropout(0.10))\n",
    "model.add(Dense(units=10, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_prop = RMSprop(lr=0.0001)\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer = rms_prop,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36000 samples, validate on 24000 samples\n",
      "Epoch 1/100\n",
      "36000/36000 [==============================] - 7s 197us/step - loss: 2.1124 - accuracy: 0.2133 - val_loss: 1.8462 - val_accuracy: 0.3013\n",
      "Epoch 2/100\n",
      "36000/36000 [==============================] - 6s 173us/step - loss: 1.7674 - accuracy: 0.3194 - val_loss: 1.6613 - val_accuracy: 0.3428\n",
      "Epoch 3/100\n",
      "36000/36000 [==============================] - 6s 166us/step - loss: 1.6020 - accuracy: 0.3657 - val_loss: 1.5294 - val_accuracy: 0.3925\n",
      "Epoch 4/100\n",
      "36000/36000 [==============================] - 6s 161us/step - loss: 1.4797 - accuracy: 0.4172 - val_loss: 1.4259 - val_accuracy: 0.4444\n",
      "Epoch 5/100\n",
      "36000/36000 [==============================] - 6s 173us/step - loss: 1.3806 - accuracy: 0.4790 - val_loss: 1.3443 - val_accuracy: 0.5204\n",
      "Epoch 6/100\n",
      "36000/36000 [==============================] - 6s 169us/step - loss: 1.2968 - accuracy: 0.5544 - val_loss: 1.2569 - val_accuracy: 0.5832\n",
      "Epoch 7/100\n",
      "36000/36000 [==============================] - 6s 171us/step - loss: 1.2160 - accuracy: 0.6013 - val_loss: 1.1819 - val_accuracy: 0.6171\n",
      "Epoch 8/100\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 1.1391 - accuracy: 0.6438 - val_loss: 1.1043 - val_accuracy: 0.6578\n",
      "Epoch 9/100\n",
      "36000/36000 [==============================] - 6s 170us/step - loss: 1.0644 - accuracy: 0.6703 - val_loss: 1.0392 - val_accuracy: 0.6650\n",
      "Epoch 10/100\n",
      "36000/36000 [==============================] - 6s 171us/step - loss: 1.0078 - accuracy: 0.6833 - val_loss: 0.9893 - val_accuracy: 0.6857\n",
      "Epoch 11/100\n",
      "36000/36000 [==============================] - 6s 175us/step - loss: 0.9466 - accuracy: 0.6977 - val_loss: 0.9232 - val_accuracy: 0.6982\n",
      "Epoch 12/100\n",
      "36000/36000 [==============================] - 6s 171us/step - loss: 0.8901 - accuracy: 0.7136 - val_loss: 0.8809 - val_accuracy: 0.7259\n",
      "Epoch 13/100\n",
      "36000/36000 [==============================] - 7s 181us/step - loss: 0.8430 - accuracy: 0.7299 - val_loss: 0.8321 - val_accuracy: 0.7255\n",
      "Epoch 14/100\n",
      "36000/36000 [==============================] - 6s 177us/step - loss: 0.8018 - accuracy: 0.7431 - val_loss: 0.8105 - val_accuracy: 0.7550\n",
      "Epoch 15/100\n",
      "36000/36000 [==============================] - 6s 172us/step - loss: 0.7680 - accuracy: 0.7575 - val_loss: 0.7614 - val_accuracy: 0.7607\n",
      "Epoch 16/100\n",
      "36000/36000 [==============================] - 6s 178us/step - loss: 0.7268 - accuracy: 0.7727 - val_loss: 0.7299 - val_accuracy: 0.7764\n",
      "Epoch 17/100\n",
      "36000/36000 [==============================] - 6s 175us/step - loss: 0.6995 - accuracy: 0.7828 - val_loss: 0.7117 - val_accuracy: 0.7715\n",
      "Epoch 18/100\n",
      "36000/36000 [==============================] - 6s 164us/step - loss: 0.6739 - accuracy: 0.7892 - val_loss: 0.6794 - val_accuracy: 0.7897\n",
      "Epoch 19/100\n",
      "36000/36000 [==============================] - 6s 176us/step - loss: 0.6453 - accuracy: 0.8019 - val_loss: 0.6571 - val_accuracy: 0.7919\n",
      "Epoch 20/100\n",
      "36000/36000 [==============================] - 6s 172us/step - loss: 0.6237 - accuracy: 0.8066 - val_loss: 0.6492 - val_accuracy: 0.7997\n",
      "Epoch 21/100\n",
      "36000/36000 [==============================] - 6s 179us/step - loss: 0.6152 - accuracy: 0.8081 - val_loss: 0.6212 - val_accuracy: 0.8040\n",
      "Epoch 22/100\n",
      "36000/36000 [==============================] - 7s 184us/step - loss: 0.5833 - accuracy: 0.8183 - val_loss: 0.6098 - val_accuracy: 0.8065\n",
      "Epoch 23/100\n",
      "36000/36000 [==============================] - 6s 169us/step - loss: 0.5748 - accuracy: 0.8198 - val_loss: 0.6086 - val_accuracy: 0.8048\n",
      "Epoch 24/100\n",
      "36000/36000 [==============================] - 6s 168us/step - loss: 0.5611 - accuracy: 0.8229 - val_loss: 0.5813 - val_accuracy: 0.8143\n",
      "Epoch 25/100\n",
      "36000/36000 [==============================] - 6s 167us/step - loss: 0.5411 - accuracy: 0.8270 - val_loss: 0.5688 - val_accuracy: 0.8175\n",
      "Epoch 26/100\n",
      "36000/36000 [==============================] - 6s 173us/step - loss: 0.5291 - accuracy: 0.8320 - val_loss: 0.5687 - val_accuracy: 0.8155\n",
      "Epoch 27/100\n",
      "36000/36000 [==============================] - 7s 185us/step - loss: 0.5259 - accuracy: 0.8310 - val_loss: 0.5577 - val_accuracy: 0.8190\n",
      "Epoch 28/100\n",
      "36000/36000 [==============================] - 7s 186us/step - loss: 0.5090 - accuracy: 0.8361 - val_loss: 0.5393 - val_accuracy: 0.8264\n",
      "Epoch 29/100\n",
      "36000/36000 [==============================] - 8s 210us/step - loss: 0.4988 - accuracy: 0.8400 - val_loss: 0.5397 - val_accuracy: 0.8249\n",
      "Epoch 30/100\n",
      "36000/36000 [==============================] - 8s 228us/step - loss: 0.4895 - accuracy: 0.8429 - val_loss: 0.5237 - val_accuracy: 0.8301\n",
      "Epoch 31/100\n",
      "36000/36000 [==============================] - 9s 238us/step - loss: 0.4782 - accuracy: 0.8448 - val_loss: 0.5286 - val_accuracy: 0.8278\n",
      "Epoch 32/100\n",
      "36000/36000 [==============================] - 8s 211us/step - loss: 0.4784 - accuracy: 0.8449 - val_loss: 0.5076 - val_accuracy: 0.8354\n",
      "Epoch 33/100\n",
      "36000/36000 [==============================] - 7s 190us/step - loss: 0.4597 - accuracy: 0.8525 - val_loss: 0.5024 - val_accuracy: 0.8337\n",
      "Epoch 34/100\n",
      "36000/36000 [==============================] - 7s 183us/step - loss: 0.4522 - accuracy: 0.8536 - val_loss: 0.4997 - val_accuracy: 0.8359\n",
      "Epoch 35/100\n",
      "36000/36000 [==============================] - 6s 175us/step - loss: 0.4581 - accuracy: 0.8511 - val_loss: 0.4978 - val_accuracy: 0.8345\n",
      "Epoch 36/100\n",
      "36000/36000 [==============================] - 6s 172us/step - loss: 0.4388 - accuracy: 0.8576 - val_loss: 0.4868 - val_accuracy: 0.8389\n",
      "Epoch 37/100\n",
      "36000/36000 [==============================] - 7s 204us/step - loss: 0.4330 - accuracy: 0.8600 - val_loss: 0.4833 - val_accuracy: 0.8409\n",
      "Epoch 38/100\n",
      "36000/36000 [==============================] - 7s 188us/step - loss: 0.4326 - accuracy: 0.8595 - val_loss: 0.4779 - val_accuracy: 0.8401\n",
      "Epoch 39/100\n",
      "36000/36000 [==============================] - 6s 171us/step - loss: 0.4211 - accuracy: 0.8628 - val_loss: 0.4729 - val_accuracy: 0.8420\n",
      "Epoch 40/100\n",
      "36000/36000 [==============================] - 6s 177us/step - loss: 0.4171 - accuracy: 0.8641 - val_loss: 0.4659 - val_accuracy: 0.8449\n",
      "Epoch 41/100\n",
      "36000/36000 [==============================] - 8s 214us/step - loss: 0.4088 - accuracy: 0.8671 - val_loss: 0.4878 - val_accuracy: 0.8365\n",
      "Epoch 42/100\n",
      "36000/36000 [==============================] - 8s 231us/step - loss: 0.4112 - accuracy: 0.8658 - val_loss: 0.4548 - val_accuracy: 0.8467\n",
      "Epoch 43/100\n",
      "36000/36000 [==============================] - 9s 245us/step - loss: 0.3969 - accuracy: 0.8708 - val_loss: 0.4538 - val_accuracy: 0.8466\n",
      "Epoch 44/100\n",
      "36000/36000 [==============================] - 8s 218us/step - loss: 0.3950 - accuracy: 0.8702 - val_loss: 0.4493 - val_accuracy: 0.8505\n",
      "Epoch 45/100\n",
      "36000/36000 [==============================] - 7s 199us/step - loss: 0.3900 - accuracy: 0.8698 - val_loss: 0.4498 - val_accuracy: 0.8487\n",
      "Epoch 46/100\n",
      "36000/36000 [==============================] - 7s 201us/step - loss: 0.3849 - accuracy: 0.8727 - val_loss: 0.4443 - val_accuracy: 0.8489\n",
      "Epoch 47/100\n",
      "36000/36000 [==============================] - 7s 205us/step - loss: 0.3829 - accuracy: 0.8729 - val_loss: 0.4422 - val_accuracy: 0.8500\n",
      "Epoch 48/100\n",
      "36000/36000 [==============================] - 7s 196us/step - loss: 0.3742 - accuracy: 0.8777 - val_loss: 0.4334 - val_accuracy: 0.8527\n",
      "Epoch 49/100\n",
      "36000/36000 [==============================] - 7s 200us/step - loss: 0.3714 - accuracy: 0.8778 - val_loss: 0.4300 - val_accuracy: 0.8547\n",
      "Epoch 50/100\n",
      "36000/36000 [==============================] - 7s 195us/step - loss: 0.3647 - accuracy: 0.8798 - val_loss: 0.4346 - val_accuracy: 0.8520\n",
      "Epoch 51/100\n",
      "36000/36000 [==============================] - 7s 193us/step - loss: 0.3690 - accuracy: 0.8764 - val_loss: 0.4264 - val_accuracy: 0.8550\n",
      "Epoch 52/100\n",
      "36000/36000 [==============================] - 7s 198us/step - loss: 0.3573 - accuracy: 0.8821 - val_loss: 0.4209 - val_accuracy: 0.8576\n",
      "Epoch 53/100\n",
      "36000/36000 [==============================] - 7s 188us/step - loss: 0.3523 - accuracy: 0.8840 - val_loss: 0.4253 - val_accuracy: 0.8545\n",
      "Epoch 54/100\n",
      "36000/36000 [==============================] - 7s 197us/step - loss: 0.3562 - accuracy: 0.8810 - val_loss: 0.4185 - val_accuracy: 0.8573\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 7s 203us/step - loss: 0.3466 - accuracy: 0.8850 - val_loss: 0.4191 - val_accuracy: 0.8579\n",
      "Epoch 56/100\n",
      "36000/36000 [==============================] - 7s 199us/step - loss: 0.3429 - accuracy: 0.8870 - val_loss: 0.4192 - val_accuracy: 0.8552\n",
      "Epoch 57/100\n",
      "36000/36000 [==============================] - 7s 203us/step - loss: 0.3476 - accuracy: 0.8836 - val_loss: 0.4085 - val_accuracy: 0.8598\n",
      "Epoch 58/100\n",
      "36000/36000 [==============================] - 7s 202us/step - loss: 0.3349 - accuracy: 0.8886 - val_loss: 0.4062 - val_accuracy: 0.8611\n",
      "Epoch 59/100\n",
      "36000/36000 [==============================] - 7s 192us/step - loss: 0.3324 - accuracy: 0.8904 - val_loss: 0.4207 - val_accuracy: 0.8547\n",
      "Epoch 60/100\n",
      "36000/36000 [==============================] - 7s 191us/step - loss: 0.3370 - accuracy: 0.8866 - val_loss: 0.4007 - val_accuracy: 0.8626\n",
      "Epoch 61/100\n",
      "36000/36000 [==============================] - 7s 195us/step - loss: 0.3266 - accuracy: 0.8923 - val_loss: 0.4071 - val_accuracy: 0.8593\n",
      "Epoch 62/100\n",
      "36000/36000 [==============================] - 7s 193us/step - loss: 0.3257 - accuracy: 0.8915 - val_loss: 0.4017 - val_accuracy: 0.8613\n",
      "Epoch 63/100\n",
      "36000/36000 [==============================] - 7s 201us/step - loss: 0.3262 - accuracy: 0.8915 - val_loss: 0.4000 - val_accuracy: 0.8614\n",
      "Epoch 64/100\n",
      "36000/36000 [==============================] - 7s 197us/step - loss: 0.3154 - accuracy: 0.8949 - val_loss: 0.4049 - val_accuracy: 0.8613\n",
      "Epoch 65/100\n",
      "36000/36000 [==============================] - 7s 196us/step - loss: 0.3182 - accuracy: 0.8936 - val_loss: 0.3971 - val_accuracy: 0.8617\n",
      "Epoch 66/100\n",
      "36000/36000 [==============================] - 7s 189us/step - loss: 0.3126 - accuracy: 0.8950 - val_loss: 0.4103 - val_accuracy: 0.8582\n",
      "Epoch 67/100\n",
      "36000/36000 [==============================] - 6s 169us/step - loss: 0.3162 - accuracy: 0.8930 - val_loss: 0.3972 - val_accuracy: 0.8620\n",
      "Epoch 68/100\n",
      "36000/36000 [==============================] - 6s 168us/step - loss: 0.3060 - accuracy: 0.8978 - val_loss: 0.3901 - val_accuracy: 0.8648\n",
      "Epoch 69/100\n",
      "36000/36000 [==============================] - 7s 185us/step - loss: 0.3057 - accuracy: 0.8984 - val_loss: 0.3912 - val_accuracy: 0.8641\n",
      "Epoch 70/100\n",
      "36000/36000 [==============================] - 7s 202us/step - loss: 0.3126 - accuracy: 0.8936 - val_loss: 0.3869 - val_accuracy: 0.8657\n",
      "Epoch 71/100\n",
      "36000/36000 [==============================] - 7s 200us/step - loss: 0.2995 - accuracy: 0.8989 - val_loss: 0.3883 - val_accuracy: 0.8640\n",
      "Epoch 72/100\n",
      "36000/36000 [==============================] - 7s 194us/step - loss: 0.2968 - accuracy: 0.9002 - val_loss: 0.3817 - val_accuracy: 0.8658\n",
      "Epoch 73/100\n",
      "36000/36000 [==============================] - 7s 188us/step - loss: 0.2923 - accuracy: 0.9013 - val_loss: 0.4017 - val_accuracy: 0.8607\n",
      "Epoch 74/100\n",
      "36000/36000 [==============================] - 7s 194us/step - loss: 0.3042 - accuracy: 0.8953 - val_loss: 0.3824 - val_accuracy: 0.8670\n",
      "Epoch 75/100\n",
      "36000/36000 [==============================] - 7s 194us/step - loss: 0.2928 - accuracy: 0.9021 - val_loss: 0.3787 - val_accuracy: 0.8687\n",
      "Epoch 76/100\n",
      "36000/36000 [==============================] - 7s 192us/step - loss: 0.2859 - accuracy: 0.9040 - val_loss: 0.3863 - val_accuracy: 0.8673\n",
      "Epoch 77/100\n",
      "36000/36000 [==============================] - 7s 194us/step - loss: 0.2876 - accuracy: 0.9027 - val_loss: 0.3958 - val_accuracy: 0.8621\n",
      "Epoch 78/100\n",
      "36000/36000 [==============================] - 7s 194us/step - loss: 0.2911 - accuracy: 0.9022 - val_loss: 0.3790 - val_accuracy: 0.8674\n",
      "Epoch 79/100\n",
      "36000/36000 [==============================] - 7s 192us/step - loss: 0.2816 - accuracy: 0.9057 - val_loss: 0.3771 - val_accuracy: 0.8685\n",
      "Epoch 80/100\n",
      "36000/36000 [==============================] - 7s 192us/step - loss: 0.2796 - accuracy: 0.9060 - val_loss: 0.3743 - val_accuracy: 0.8699\n",
      "Epoch 81/100\n",
      "36000/36000 [==============================] - 7s 195us/step - loss: 0.2848 - accuracy: 0.9038 - val_loss: 0.3859 - val_accuracy: 0.8648\n",
      "Epoch 82/100\n",
      "36000/36000 [==============================] - 7s 194us/step - loss: 0.2769 - accuracy: 0.9074 - val_loss: 0.3709 - val_accuracy: 0.8704\n",
      "Epoch 83/100\n",
      "36000/36000 [==============================] - 7s 192us/step - loss: 0.2734 - accuracy: 0.9086 - val_loss: 0.3732 - val_accuracy: 0.8688\n",
      "Epoch 84/100\n",
      "36000/36000 [==============================] - 7s 191us/step - loss: 0.2729 - accuracy: 0.9084 - val_loss: 0.3803 - val_accuracy: 0.8669\n",
      "Epoch 85/100\n",
      "36000/36000 [==============================] - 7s 197us/step - loss: 0.2773 - accuracy: 0.9053 - val_loss: 0.3760 - val_accuracy: 0.8697\n",
      "Epoch 86/100\n",
      "36000/36000 [==============================] - 8s 210us/step - loss: 0.2705 - accuracy: 0.9080 - val_loss: 0.3723 - val_accuracy: 0.8692\n",
      "Epoch 87/100\n",
      "36000/36000 [==============================] - 7s 205us/step - loss: 0.2703 - accuracy: 0.9079 - val_loss: 0.3738 - val_accuracy: 0.8702\n",
      "Epoch 88/100\n",
      "36000/36000 [==============================] - 8s 227us/step - loss: 0.2648 - accuracy: 0.9100 - val_loss: 0.3752 - val_accuracy: 0.8686\n",
      "Epoch 89/100\n",
      "36000/36000 [==============================] - 7s 199us/step - loss: 0.2639 - accuracy: 0.9111 - val_loss: 0.3688 - val_accuracy: 0.8705\n",
      "Epoch 90/100\n",
      "36000/36000 [==============================] - 7s 195us/step - loss: 0.2657 - accuracy: 0.9099 - val_loss: 0.3893 - val_accuracy: 0.8641\n",
      "Epoch 91/100\n",
      "36000/36000 [==============================] - 8s 217us/step - loss: 0.2687 - accuracy: 0.9081 - val_loss: 0.3665 - val_accuracy: 0.8725\n",
      "Epoch 92/100\n",
      "36000/36000 [==============================] - 8s 210us/step - loss: 0.2581 - accuracy: 0.9135 - val_loss: 0.3767 - val_accuracy: 0.8692\n",
      "Epoch 93/100\n",
      "36000/36000 [==============================] - 7s 196us/step - loss: 0.2568 - accuracy: 0.9138 - val_loss: 0.3648 - val_accuracy: 0.8725\n",
      "Epoch 94/100\n",
      "36000/36000 [==============================] - 7s 202us/step - loss: 0.2579 - accuracy: 0.9121 - val_loss: 0.3719 - val_accuracy: 0.8717\n",
      "Epoch 95/100\n",
      "36000/36000 [==============================] - 7s 199us/step - loss: 0.2550 - accuracy: 0.9150 - val_loss: 0.3914 - val_accuracy: 0.8661\n",
      "Epoch 96/100\n",
      "36000/36000 [==============================] - 7s 186us/step - loss: 0.2617 - accuracy: 0.9110 - val_loss: 0.3616 - val_accuracy: 0.8740\n",
      "Epoch 97/100\n",
      "36000/36000 [==============================] - 7s 200us/step - loss: 0.2465 - accuracy: 0.9180 - val_loss: 0.3710 - val_accuracy: 0.8712\n",
      "Epoch 98/100\n",
      "36000/36000 [==============================] - 7s 201us/step - loss: 0.2552 - accuracy: 0.9129 - val_loss: 0.3680 - val_accuracy: 0.8733\n",
      "Epoch 99/100\n",
      "36000/36000 [==============================] - 7s 194us/step - loss: 0.2511 - accuracy: 0.9161 - val_loss: 0.3739 - val_accuracy: 0.8708\n",
      "Epoch 100/100\n",
      "36000/36000 [==============================] - 7s 202us/step - loss: 0.2454 - accuracy: 0.9178 - val_loss: 0.3651 - val_accuracy: 0.8739\n"
     ]
    }
   ],
   "source": [
    "hist_rand = model.fit(train_input.values, train_label, epochs = 100, batch_size = 8192, validation_split = 0.4, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(hist_rand.history['val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_x = keras.models.Sequential()\n",
    "model_x.add(Dense(units=1024, input_dim=train_input.shape[1], activation=\"relu\"))\n",
    "#model.add(Dropout(0.30))\n",
    "model_x.add(Dense(units=200, activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "#model.add(Dropout(0.25))\n",
    "model_x.add(Dense(units=20, activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "#model.add(Dropout(0.20))\n",
    "model_x.add(Dense(units=20, activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "#model.add(Dropout(0.15))\n",
    "model_x.add(Dense(units=20, activation=\"relu\", kernel_initializer='glorot_uniform'))\n",
    "#model.add(Dropout(0.10))\n",
    "model_x.add(Dense(units=10, activation=\"softmax\", kernel_initializer='glorot_uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_prop = RMSprop(lr=0.0001)\n",
    "model_x.compile(loss='categorical_crossentropy', \n",
    "              optimizer = rms_prop,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36000 samples, validate on 24000 samples\n",
      "Epoch 1/100\n",
      "36000/36000 [==============================] - 8s 210us/step - loss: 2.1516 - accuracy: 0.2024 - val_loss: 1.8840 - val_accuracy: 0.2838\n",
      "Epoch 2/100\n",
      "36000/36000 [==============================] - 6s 180us/step - loss: 1.7966 - accuracy: 0.3244 - val_loss: 1.6715 - val_accuracy: 0.3868\n",
      "Epoch 3/100\n",
      "36000/36000 [==============================] - 7s 197us/step - loss: 1.6134 - accuracy: 0.4111 - val_loss: 1.5360 - val_accuracy: 0.4446\n",
      "Epoch 4/100\n",
      "36000/36000 [==============================] - 7s 186us/step - loss: 1.4894 - accuracy: 0.4702 - val_loss: 1.4303 - val_accuracy: 0.5132\n",
      "Epoch 5/100\n",
      "36000/36000 [==============================] - 6s 178us/step - loss: 1.3863 - accuracy: 0.5341 - val_loss: 1.3341 - val_accuracy: 0.5797\n",
      "Epoch 6/100\n",
      "36000/36000 [==============================] - 6s 179us/step - loss: 1.2970 - accuracy: 0.5905 - val_loss: 1.2522 - val_accuracy: 0.6111\n",
      "Epoch 7/100\n",
      "36000/36000 [==============================] - 7s 189us/step - loss: 1.2110 - accuracy: 0.6309 - val_loss: 1.1694 - val_accuracy: 0.6481\n",
      "Epoch 8/100\n",
      "36000/36000 [==============================] - 7s 191us/step - loss: 1.1320 - accuracy: 0.6512 - val_loss: 1.0970 - val_accuracy: 0.6473\n",
      "Epoch 9/100\n",
      "36000/36000 [==============================] - 7s 201us/step - loss: 1.0629 - accuracy: 0.6568 - val_loss: 1.0342 - val_accuracy: 0.6664\n",
      "Epoch 10/100\n",
      "36000/36000 [==============================] - 7s 183us/step - loss: 1.0018 - accuracy: 0.6673 - val_loss: 0.9811 - val_accuracy: 0.6646\n",
      "Epoch 11/100\n",
      "36000/36000 [==============================] - 6s 175us/step - loss: 0.9475 - accuracy: 0.6739 - val_loss: 0.9294 - val_accuracy: 0.6676\n",
      "Epoch 12/100\n",
      "36000/36000 [==============================] - 7s 189us/step - loss: 0.8968 - accuracy: 0.6786 - val_loss: 0.8874 - val_accuracy: 0.6793\n",
      "Epoch 13/100\n",
      "36000/36000 [==============================] - 6s 175us/step - loss: 0.8551 - accuracy: 0.6842 - val_loss: 0.8549 - val_accuracy: 0.6656\n",
      "Epoch 14/100\n",
      "36000/36000 [==============================] - 7s 187us/step - loss: 0.8163 - accuracy: 0.6864 - val_loss: 0.8118 - val_accuracy: 0.6874\n",
      "Epoch 15/100\n",
      "36000/36000 [==============================] - 6s 170us/step - loss: 0.7820 - accuracy: 0.6934 - val_loss: 0.7835 - val_accuracy: 0.6819\n",
      "Epoch 16/100\n",
      "36000/36000 [==============================] - 7s 181us/step - loss: 0.7459 - accuracy: 0.6990 - val_loss: 0.7556 - val_accuracy: 0.6976\n",
      "Epoch 17/100\n",
      "36000/36000 [==============================] - 7s 192us/step - loss: 0.7201 - accuracy: 0.7066 - val_loss: 0.7258 - val_accuracy: 0.7120\n",
      "Epoch 18/100\n",
      "36000/36000 [==============================] - 6s 170us/step - loss: 0.6879 - accuracy: 0.7334 - val_loss: 0.6940 - val_accuracy: 0.7557\n",
      "Epoch 19/100\n",
      "36000/36000 [==============================] - 7s 184us/step - loss: 0.6612 - accuracy: 0.7760 - val_loss: 0.6861 - val_accuracy: 0.7557\n",
      "Epoch 20/100\n",
      "36000/36000 [==============================] - 7s 195us/step - loss: 0.6415 - accuracy: 0.7893 - val_loss: 0.6497 - val_accuracy: 0.7943\n",
      "Epoch 21/100\n",
      "36000/36000 [==============================] - 8s 220us/step - loss: 0.6115 - accuracy: 0.8084 - val_loss: 0.6254 - val_accuracy: 0.7980\n",
      "Epoch 22/100\n",
      "36000/36000 [==============================] - 7s 200us/step - loss: 0.5900 - accuracy: 0.8168 - val_loss: 0.6201 - val_accuracy: 0.8052\n",
      "Epoch 23/100\n",
      "36000/36000 [==============================] - 7s 204us/step - loss: 0.5794 - accuracy: 0.8173 - val_loss: 0.5901 - val_accuracy: 0.8114\n",
      "Epoch 24/100\n",
      "36000/36000 [==============================] - 6s 167us/step - loss: 0.5539 - accuracy: 0.8248 - val_loss: 0.5840 - val_accuracy: 0.8115\n",
      "Epoch 25/100\n",
      "36000/36000 [==============================] - 7s 204us/step - loss: 0.5408 - accuracy: 0.8266 - val_loss: 0.5622 - val_accuracy: 0.8190\n",
      "Epoch 26/100\n",
      "36000/36000 [==============================] - 7s 186us/step - loss: 0.5239 - accuracy: 0.8337 - val_loss: 0.5513 - val_accuracy: 0.8215\n",
      "Epoch 27/100\n",
      "36000/36000 [==============================] - 7s 204us/step - loss: 0.5101 - accuracy: 0.8364 - val_loss: 0.5394 - val_accuracy: 0.8239\n",
      "Epoch 28/100\n",
      "36000/36000 [==============================] - 7s 183us/step - loss: 0.5005 - accuracy: 0.8379 - val_loss: 0.5306 - val_accuracy: 0.8253\n",
      "Epoch 29/100\n",
      "36000/36000 [==============================] - 7s 183us/step - loss: 0.4867 - accuracy: 0.8428 - val_loss: 0.5108 - val_accuracy: 0.8334\n",
      "Epoch 30/100\n",
      "36000/36000 [==============================] - 6s 179us/step - loss: 0.4754 - accuracy: 0.8443 - val_loss: 0.5079 - val_accuracy: 0.8312\n",
      "Epoch 31/100\n",
      "36000/36000 [==============================] - 6s 176us/step - loss: 0.4722 - accuracy: 0.8427 - val_loss: 0.4997 - val_accuracy: 0.8337\n",
      "Epoch 32/100\n",
      "36000/36000 [==============================] - 6s 177us/step - loss: 0.4565 - accuracy: 0.8511 - val_loss: 0.4886 - val_accuracy: 0.8369\n",
      "Epoch 33/100\n",
      "36000/36000 [==============================] - 6s 175us/step - loss: 0.4554 - accuracy: 0.8489 - val_loss: 0.4846 - val_accuracy: 0.8376\n",
      "Epoch 34/100\n",
      "36000/36000 [==============================] - 7s 184us/step - loss: 0.4449 - accuracy: 0.8523 - val_loss: 0.4908 - val_accuracy: 0.8325\n",
      "Epoch 35/100\n",
      "36000/36000 [==============================] - 7s 181us/step - loss: 0.4367 - accuracy: 0.8567 - val_loss: 0.4698 - val_accuracy: 0.8422\n",
      "Epoch 36/100\n",
      "36000/36000 [==============================] - 7s 187us/step - loss: 0.4296 - accuracy: 0.8575 - val_loss: 0.4774 - val_accuracy: 0.8380\n",
      "Epoch 37/100\n",
      "36000/36000 [==============================] - 6s 173us/step - loss: 0.4256 - accuracy: 0.8596 - val_loss: 0.4605 - val_accuracy: 0.8436\n",
      "Epoch 38/100\n",
      "36000/36000 [==============================] - 6s 173us/step - loss: 0.4259 - accuracy: 0.8569 - val_loss: 0.4572 - val_accuracy: 0.8439\n",
      "Epoch 39/100\n",
      "36000/36000 [==============================] - 10s 281us/step - loss: 0.4105 - accuracy: 0.8640 - val_loss: 0.4563 - val_accuracy: 0.8462\n",
      "Epoch 40/100\n",
      "36000/36000 [==============================] - 12s 346us/step - loss: 0.4125 - accuracy: 0.8602 - val_loss: 0.4518 - val_accuracy: 0.8442\n",
      "Epoch 41/100\n",
      "36000/36000 [==============================] - 13s 349us/step - loss: 0.4044 - accuracy: 0.8645 - val_loss: 0.4539 - val_accuracy: 0.8444\n",
      "Epoch 42/100\n",
      "36000/36000 [==============================] - 12s 339us/step - loss: 0.4005 - accuracy: 0.8652 - val_loss: 0.4399 - val_accuracy: 0.8487\n",
      "Epoch 43/100\n",
      "36000/36000 [==============================] - 12s 334us/step - loss: 0.3924 - accuracy: 0.8692 - val_loss: 0.4415 - val_accuracy: 0.8503\n",
      "Epoch 44/100\n",
      "36000/36000 [==============================] - 12s 332us/step - loss: 0.4012 - accuracy: 0.8626 - val_loss: 0.4349 - val_accuracy: 0.8497\n",
      "Epoch 45/100\n",
      "36000/36000 [==============================] - 12s 340us/step - loss: 0.3838 - accuracy: 0.8717 - val_loss: 0.4405 - val_accuracy: 0.8499\n",
      "Epoch 46/100\n",
      "36000/36000 [==============================] - 9s 252us/step - loss: 0.3852 - accuracy: 0.8704 - val_loss: 0.4325 - val_accuracy: 0.8504\n",
      "Epoch 47/100\n",
      "36000/36000 [==============================] - 11s 318us/step - loss: 0.3826 - accuracy: 0.8707 - val_loss: 0.4287 - val_accuracy: 0.8530\n",
      "Epoch 48/100\n",
      "36000/36000 [==============================] - 12s 339us/step - loss: 0.3750 - accuracy: 0.8732 - val_loss: 0.4301 - val_accuracy: 0.8525\n",
      "Epoch 49/100\n",
      "36000/36000 [==============================] - 13s 349us/step - loss: 0.3701 - accuracy: 0.8745 - val_loss: 0.4176 - val_accuracy: 0.8575\n",
      "Epoch 50/100\n",
      "36000/36000 [==============================] - 13s 347us/step - loss: 0.3640 - accuracy: 0.8777 - val_loss: 0.4344 - val_accuracy: 0.8488\n",
      "Epoch 51/100\n",
      "36000/36000 [==============================] - 13s 348us/step - loss: 0.3749 - accuracy: 0.8711 - val_loss: 0.4163 - val_accuracy: 0.8556\n",
      "Epoch 52/100\n",
      "36000/36000 [==============================] - 13s 354us/step - loss: 0.3582 - accuracy: 0.8803 - val_loss: 0.4156 - val_accuracy: 0.8586\n",
      "Epoch 53/100\n",
      "36000/36000 [==============================] - 15s 422us/step - loss: 0.3619 - accuracy: 0.8779 - val_loss: 0.4201 - val_accuracy: 0.8544\n",
      "Epoch 54/100\n",
      "36000/36000 [==============================] - 16s 448us/step - loss: 0.3560 - accuracy: 0.8799 - val_loss: 0.4101 - val_accuracy: 0.8595\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 18s 510us/step - loss: 0.3509 - accuracy: 0.8819 - val_loss: 0.4147 - val_accuracy: 0.8570\n",
      "Epoch 56/100\n",
      "36000/36000 [==============================] - 17s 469us/step - loss: 0.3532 - accuracy: 0.8815 - val_loss: 0.4166 - val_accuracy: 0.8530\n",
      "Epoch 57/100\n",
      "36000/36000 [==============================] - 18s 491us/step - loss: 0.3490 - accuracy: 0.8808 - val_loss: 0.4036 - val_accuracy: 0.8600\n",
      "Epoch 58/100\n",
      "36000/36000 [==============================] - 16s 456us/step - loss: 0.3430 - accuracy: 0.8829 - val_loss: 0.4046 - val_accuracy: 0.8612\n",
      "Epoch 59/100\n",
      "36000/36000 [==============================] - 16s 450us/step - loss: 0.3470 - accuracy: 0.8817 - val_loss: 0.4071 - val_accuracy: 0.8562\n",
      "Epoch 60/100\n",
      "36000/36000 [==============================] - 15s 424us/step - loss: 0.3394 - accuracy: 0.8851 - val_loss: 0.3974 - val_accuracy: 0.8638\n",
      "Epoch 61/100\n",
      "36000/36000 [==============================] - 16s 444us/step - loss: 0.3315 - accuracy: 0.8887 - val_loss: 0.4006 - val_accuracy: 0.8620\n",
      "Epoch 62/100\n",
      "36000/36000 [==============================] - 16s 452us/step - loss: 0.3416 - accuracy: 0.8824 - val_loss: 0.3988 - val_accuracy: 0.8625\n",
      "Epoch 63/100\n",
      "36000/36000 [==============================] - 15s 418us/step - loss: 0.3313 - accuracy: 0.8875 - val_loss: 0.4018 - val_accuracy: 0.8565\n",
      "Epoch 64/100\n",
      "36000/36000 [==============================] - 17s 459us/step - loss: 0.3327 - accuracy: 0.8865 - val_loss: 0.4028 - val_accuracy: 0.8607\n",
      "Epoch 65/100\n",
      "36000/36000 [==============================] - 12s 343us/step - loss: 0.3254 - accuracy: 0.8888 - val_loss: 0.3912 - val_accuracy: 0.8640\n",
      "Epoch 66/100\n",
      "36000/36000 [==============================] - 13s 348us/step - loss: 0.3201 - accuracy: 0.8913 - val_loss: 0.3965 - val_accuracy: 0.8633\n",
      "Epoch 67/100\n",
      "36000/36000 [==============================] - 12s 344us/step - loss: 0.3343 - accuracy: 0.8828 - val_loss: 0.3943 - val_accuracy: 0.8615\n",
      "Epoch 68/100\n",
      "36000/36000 [==============================] - 13s 365us/step - loss: 0.3169 - accuracy: 0.8926 - val_loss: 0.3864 - val_accuracy: 0.8640\n",
      "Epoch 69/100\n",
      "36000/36000 [==============================] - 12s 341us/step - loss: 0.3179 - accuracy: 0.8913 - val_loss: 0.4019 - val_accuracy: 0.8622\n",
      "Epoch 70/100\n",
      "36000/36000 [==============================] - 13s 349us/step - loss: 0.3195 - accuracy: 0.8911 - val_loss: 0.3951 - val_accuracy: 0.8612\n",
      "Epoch 71/100\n",
      "36000/36000 [==============================] - 13s 373us/step - loss: 0.3173 - accuracy: 0.8913 - val_loss: 0.3872 - val_accuracy: 0.8673\n",
      "Epoch 72/100\n",
      "36000/36000 [==============================] - 12s 330us/step - loss: 0.3094 - accuracy: 0.8943 - val_loss: 0.3864 - val_accuracy: 0.8669\n",
      "Epoch 73/100\n",
      "36000/36000 [==============================] - 13s 349us/step - loss: 0.3129 - accuracy: 0.8918 - val_loss: 0.3860 - val_accuracy: 0.8641\n",
      "Epoch 74/100\n",
      "36000/36000 [==============================] - 12s 333us/step - loss: 0.3098 - accuracy: 0.8930 - val_loss: 0.3915 - val_accuracy: 0.8630\n",
      "Epoch 75/100\n",
      "36000/36000 [==============================] - 12s 336us/step - loss: 0.3114 - accuracy: 0.8914 - val_loss: 0.3815 - val_accuracy: 0.8668\n",
      "Epoch 76/100\n",
      "36000/36000 [==============================] - 13s 359us/step - loss: 0.3026 - accuracy: 0.8963 - val_loss: 0.3879 - val_accuracy: 0.8647\n",
      "Epoch 77/100\n",
      "36000/36000 [==============================] - 13s 357us/step - loss: 0.3049 - accuracy: 0.8945 - val_loss: 0.3805 - val_accuracy: 0.8660\n",
      "Epoch 78/100\n",
      "36000/36000 [==============================] - 12s 337us/step - loss: 0.3033 - accuracy: 0.8952 - val_loss: 0.3884 - val_accuracy: 0.8658\n",
      "Epoch 79/100\n",
      "36000/36000 [==============================] - 13s 351us/step - loss: 0.2992 - accuracy: 0.8972 - val_loss: 0.3733 - val_accuracy: 0.8693\n",
      "Epoch 80/100\n",
      "36000/36000 [==============================] - 13s 365us/step - loss: 0.2956 - accuracy: 0.8989 - val_loss: 0.3851 - val_accuracy: 0.8648\n",
      "Epoch 81/100\n",
      "36000/36000 [==============================] - 13s 352us/step - loss: 0.3010 - accuracy: 0.8947 - val_loss: 0.3922 - val_accuracy: 0.8620\n",
      "Epoch 82/100\n",
      "36000/36000 [==============================] - 13s 367us/step - loss: 0.2973 - accuracy: 0.8964 - val_loss: 0.3759 - val_accuracy: 0.8701\n",
      "Epoch 83/100\n",
      "36000/36000 [==============================] - 13s 365us/step - loss: 0.2899 - accuracy: 0.8999 - val_loss: 0.3753 - val_accuracy: 0.8665\n",
      "Epoch 84/100\n",
      "36000/36000 [==============================] - 16s 452us/step - loss: 0.2958 - accuracy: 0.8974 - val_loss: 0.3931 - val_accuracy: 0.8628\n",
      "Epoch 85/100\n",
      "36000/36000 [==============================] - 17s 484us/step - loss: 0.2896 - accuracy: 0.8992 - val_loss: 0.3701 - val_accuracy: 0.8710\n",
      "Epoch 86/100\n",
      "36000/36000 [==============================] - 15s 430us/step - loss: 0.2830 - accuracy: 0.9022 - val_loss: 0.3842 - val_accuracy: 0.8635\n",
      "Epoch 87/100\n",
      "36000/36000 [==============================] - 15s 407us/step - loss: 0.3003 - accuracy: 0.8933 - val_loss: 0.3708 - val_accuracy: 0.8714\n",
      "Epoch 88/100\n",
      "36000/36000 [==============================] - 14s 381us/step - loss: 0.2783 - accuracy: 0.9045 - val_loss: 0.3706 - val_accuracy: 0.8711\n",
      "Epoch 89/100\n",
      "36000/36000 [==============================] - 15s 403us/step - loss: 0.2864 - accuracy: 0.8997 - val_loss: 0.3777 - val_accuracy: 0.8674\n",
      "Epoch 90/100\n",
      "36000/36000 [==============================] - 14s 379us/step - loss: 0.2824 - accuracy: 0.9027 - val_loss: 0.3670 - val_accuracy: 0.8741\n",
      "Epoch 91/100\n",
      "36000/36000 [==============================] - 14s 385us/step - loss: 0.2794 - accuracy: 0.9037 - val_loss: 0.3693 - val_accuracy: 0.8704\n",
      "Epoch 92/100\n",
      "36000/36000 [==============================] - 12s 347us/step - loss: 0.2819 - accuracy: 0.9019 - val_loss: 0.3884 - val_accuracy: 0.8639\n",
      "Epoch 93/100\n",
      "36000/36000 [==============================] - 13s 355us/step - loss: 0.2823 - accuracy: 0.9011 - val_loss: 0.3682 - val_accuracy: 0.8726\n",
      "Epoch 94/100\n",
      "36000/36000 [==============================] - 13s 356us/step - loss: 0.2776 - accuracy: 0.9041 - val_loss: 0.3718 - val_accuracy: 0.8692\n",
      "Epoch 95/100\n",
      "36000/36000 [==============================] - 13s 360us/step - loss: 0.2735 - accuracy: 0.9036 - val_loss: 0.3671 - val_accuracy: 0.8717\n",
      "Epoch 96/100\n",
      "36000/36000 [==============================] - 14s 395us/step - loss: 0.2783 - accuracy: 0.9022 - val_loss: 0.3737 - val_accuracy: 0.8703\n",
      "Epoch 97/100\n",
      "36000/36000 [==============================] - 13s 352us/step - loss: 0.2731 - accuracy: 0.9056 - val_loss: 0.3632 - val_accuracy: 0.8728\n",
      "Epoch 98/100\n",
      "36000/36000 [==============================] - 13s 372us/step - loss: 0.2688 - accuracy: 0.9066 - val_loss: 0.3762 - val_accuracy: 0.8698\n",
      "Epoch 99/100\n",
      "36000/36000 [==============================] - 15s 406us/step - loss: 0.2763 - accuracy: 0.9030 - val_loss: 0.3680 - val_accuracy: 0.8704\n",
      "Epoch 100/100\n",
      "36000/36000 [==============================] - 15s 415us/step - loss: 0.2687 - accuracy: 0.9076 - val_loss: 0.3712 - val_accuracy: 0.8688\n"
     ]
    }
   ],
   "source": [
    "hist_xav = model_x.fit(train_input.values, train_label, epochs = 100, batch_size = 8192, validation_split = 0.4, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist_xav.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.savez(\"fashion_mnist_relu\", xav_loss = hist_xav.history['val_loss'], xav_acc = hist_xav.history['val_accuracy'], \n",
    "         rand_loss = hist_rand.history['val_loss'], rand_acc = hist_rand.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_o = keras.models.Sequential()\n",
    "model_o.add(Dense(units=1024, input_dim=train_input.shape[1], activation=\"relu\"))\n",
    "#model.add(Dropout(0.30))\n",
    "model_o.add(Dense(units=200, activation=\"relu\", kernel_initializer='orthogonal'))\n",
    "#model.add(Dropout(0.25))\n",
    "model_o.add(Dense(units=20, activation=\"relu\", kernel_initializer='orthogonal'))\n",
    "#model.add(Dropout(0.20))\n",
    "model_o.add(Dense(units=20, activation=\"relu\", kernel_initializer='orthogonal'))\n",
    "#model.add(Dropout(0.15))\n",
    "model_o.add(Dense(units=20, activation=\"relu\", kernel_initializer='orthogonal'))\n",
    "#model.add(Dropout(0.10))\n",
    "model_o.add(Dense(units=10, activation=\"softmax\", kernel_initializer='orthogonal'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_prop = RMSprop(lr=0.0001)\n",
    "model_o.compile(loss='categorical_crossentropy', \n",
    "              optimizer = rms_prop,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36000 samples, validate on 24000 samples\n",
      "Epoch 1/100\n",
      "36000/36000 [==============================] - 15s 421us/step - loss: 2.2035 - accuracy: 0.1908 - val_loss: 2.0389 - val_accuracy: 0.3165\n",
      "Epoch 2/100\n",
      "36000/36000 [==============================] - 13s 351us/step - loss: 1.9737 - accuracy: 0.3382 - val_loss: 1.8637 - val_accuracy: 0.3943\n",
      "Epoch 3/100\n",
      "36000/36000 [==============================] - 13s 349us/step - loss: 1.8004 - accuracy: 0.4293 - val_loss: 1.7032 - val_accuracy: 0.4632\n",
      "Epoch 4/100\n",
      "36000/36000 [==============================] - 13s 349us/step - loss: 1.6522 - accuracy: 0.4687 - val_loss: 1.5764 - val_accuracy: 0.4858\n",
      "Epoch 5/100\n",
      "36000/36000 [==============================] - 13s 367us/step - loss: 1.5353 - accuracy: 0.4961 - val_loss: 1.4751 - val_accuracy: 0.5265\n",
      "Epoch 6/100\n",
      "36000/36000 [==============================] - 12s 347us/step - loss: 1.4395 - accuracy: 0.5322 - val_loss: 1.3907 - val_accuracy: 0.5578\n",
      "Epoch 7/100\n",
      "36000/36000 [==============================] - 12s 341us/step - loss: 1.3588 - accuracy: 0.5625 - val_loss: 1.3180 - val_accuracy: 0.5800\n",
      "Epoch 8/100\n",
      "36000/36000 [==============================] - 12s 342us/step - loss: 1.2896 - accuracy: 0.5861 - val_loss: 1.2558 - val_accuracy: 0.6096\n",
      "Epoch 9/100\n",
      "36000/36000 [==============================] - 12s 342us/step - loss: 1.2298 - accuracy: 0.6070 - val_loss: 1.2018 - val_accuracy: 0.6140\n",
      "Epoch 10/100\n",
      "36000/36000 [==============================] - 13s 359us/step - loss: 1.1749 - accuracy: 0.6263 - val_loss: 1.1524 - val_accuracy: 0.6360\n",
      "Epoch 11/100\n",
      "36000/36000 [==============================] - 15s 418us/step - loss: 1.1263 - accuracy: 0.6431 - val_loss: 1.1069 - val_accuracy: 0.6453\n",
      "Epoch 12/100\n",
      "36000/36000 [==============================] - 15s 410us/step - loss: 1.0829 - accuracy: 0.6569 - val_loss: 1.0673 - val_accuracy: 0.6648\n",
      "Epoch 13/100\n",
      "36000/36000 [==============================] - 15s 412us/step - loss: 1.0420 - accuracy: 0.6708 - val_loss: 1.0298 - val_accuracy: 0.6712\n",
      "Epoch 14/100\n",
      "36000/36000 [==============================] - 12s 321us/step - loss: 1.0051 - accuracy: 0.6799 - val_loss: 0.9932 - val_accuracy: 0.6890\n",
      "Epoch 15/100\n",
      "36000/36000 [==============================] - 14s 398us/step - loss: 0.9690 - accuracy: 0.6891 - val_loss: 0.9609 - val_accuracy: 0.6937\n",
      "Epoch 16/100\n",
      "36000/36000 [==============================] - 15s 404us/step - loss: 0.9359 - accuracy: 0.6968 - val_loss: 0.9314 - val_accuracy: 0.6993\n",
      "Epoch 17/100\n",
      "36000/36000 [==============================] - 12s 339us/step - loss: 0.9044 - accuracy: 0.7039 - val_loss: 0.9003 - val_accuracy: 0.7063\n",
      "Epoch 18/100\n",
      "36000/36000 [==============================] - 12s 337us/step - loss: 0.8779 - accuracy: 0.7087 - val_loss: 0.8785 - val_accuracy: 0.7098\n",
      "Epoch 19/100\n",
      "36000/36000 [==============================] - 15s 416us/step - loss: 0.8510 - accuracy: 0.7136 - val_loss: 0.8543 - val_accuracy: 0.7203\n",
      "Epoch 20/100\n",
      "36000/36000 [==============================] - 17s 463us/step - loss: 0.8277 - accuracy: 0.7198 - val_loss: 0.8290 - val_accuracy: 0.7189\n",
      "Epoch 21/100\n",
      "36000/36000 [==============================] - 16s 448us/step - loss: 0.8024 - accuracy: 0.7250 - val_loss: 0.8056 - val_accuracy: 0.7232\n",
      "Epoch 22/100\n",
      "36000/36000 [==============================] - 11s 319us/step - loss: 0.7784 - accuracy: 0.7301 - val_loss: 0.7898 - val_accuracy: 0.7263\n",
      "Epoch 23/100\n",
      "36000/36000 [==============================] - 12s 332us/step - loss: 0.7560 - accuracy: 0.7349 - val_loss: 0.7639 - val_accuracy: 0.7345\n",
      "Epoch 24/100\n",
      "36000/36000 [==============================] - 11s 314us/step - loss: 0.7351 - accuracy: 0.7387 - val_loss: 0.7491 - val_accuracy: 0.7301\n",
      "Epoch 25/100\n",
      "36000/36000 [==============================] - 11s 304us/step - loss: 0.7146 - accuracy: 0.7480 - val_loss: 0.7254 - val_accuracy: 0.7658\n",
      "Epoch 26/100\n",
      "36000/36000 [==============================] - 11s 309us/step - loss: 0.6921 - accuracy: 0.7894 - val_loss: 0.7083 - val_accuracy: 0.7969\n",
      "Epoch 27/100\n",
      "36000/36000 [==============================] - 12s 331us/step - loss: 0.6731 - accuracy: 0.8083 - val_loss: 0.6896 - val_accuracy: 0.8033\n",
      "Epoch 28/100\n",
      "36000/36000 [==============================] - 11s 309us/step - loss: 0.6535 - accuracy: 0.8175 - val_loss: 0.6744 - val_accuracy: 0.8078\n",
      "Epoch 29/100\n",
      "36000/36000 [==============================] - 11s 309us/step - loss: 0.6403 - accuracy: 0.8186 - val_loss: 0.6555 - val_accuracy: 0.8114\n",
      "Epoch 30/100\n",
      "36000/36000 [==============================] - 16s 431us/step - loss: 0.6184 - accuracy: 0.8266 - val_loss: 0.6404 - val_accuracy: 0.8195\n",
      "Epoch 31/100\n",
      "36000/36000 [==============================] - 15s 427us/step - loss: 0.6034 - accuracy: 0.8314 - val_loss: 0.6264 - val_accuracy: 0.8200\n",
      "Epoch 32/100\n",
      "36000/36000 [==============================] - 15s 419us/step - loss: 0.5863 - accuracy: 0.8340 - val_loss: 0.6134 - val_accuracy: 0.8238\n",
      "Epoch 33/100\n",
      "36000/36000 [==============================] - 14s 385us/step - loss: 0.5752 - accuracy: 0.8363 - val_loss: 0.6003 - val_accuracy: 0.8267\n",
      "Epoch 34/100\n",
      "36000/36000 [==============================] - 15s 424us/step - loss: 0.5555 - accuracy: 0.8420 - val_loss: 0.5845 - val_accuracy: 0.8285\n",
      "Epoch 35/100\n",
      "36000/36000 [==============================] - 14s 383us/step - loss: 0.5441 - accuracy: 0.8431 - val_loss: 0.5820 - val_accuracy: 0.8298\n",
      "Epoch 36/100\n",
      "36000/36000 [==============================] - 10s 283us/step - loss: 0.5316 - accuracy: 0.8458 - val_loss: 0.5640 - val_accuracy: 0.8343\n",
      "Epoch 37/100\n",
      "36000/36000 [==============================] - 10s 268us/step - loss: 0.5193 - accuracy: 0.8484 - val_loss: 0.5531 - val_accuracy: 0.8371\n",
      "Epoch 38/100\n",
      "36000/36000 [==============================] - 8s 222us/step - loss: 0.5094 - accuracy: 0.8511 - val_loss: 0.5444 - val_accuracy: 0.8352\n",
      "Epoch 39/100\n",
      "36000/36000 [==============================] - 6s 170us/step - loss: 0.5015 - accuracy: 0.8520 - val_loss: 0.5366 - val_accuracy: 0.8392\n",
      "Epoch 40/100\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.4875 - accuracy: 0.8548 - val_loss: 0.5268 - val_accuracy: 0.8422\n",
      "Epoch 41/100\n",
      "36000/36000 [==============================] - 6s 166us/step - loss: 0.4781 - accuracy: 0.8577 - val_loss: 0.5245 - val_accuracy: 0.8393\n",
      "Epoch 42/100\n",
      "36000/36000 [==============================] - 6s 161us/step - loss: 0.4750 - accuracy: 0.8573 - val_loss: 0.5140 - val_accuracy: 0.8410\n",
      "Epoch 43/100\n",
      "36000/36000 [==============================] - 6s 167us/step - loss: 0.4641 - accuracy: 0.8606 - val_loss: 0.5048 - val_accuracy: 0.8452\n",
      "Epoch 44/100\n",
      "36000/36000 [==============================] - 6s 157us/step - loss: 0.4551 - accuracy: 0.8622 - val_loss: 0.4991 - val_accuracy: 0.8468\n",
      "Epoch 45/100\n",
      "36000/36000 [==============================] - 6s 157us/step - loss: 0.4484 - accuracy: 0.8647 - val_loss: 0.4971 - val_accuracy: 0.8463\n",
      "Epoch 46/100\n",
      "36000/36000 [==============================] - 6s 161us/step - loss: 0.4430 - accuracy: 0.8639 - val_loss: 0.4864 - val_accuracy: 0.8477\n",
      "Epoch 47/100\n",
      "36000/36000 [==============================] - 6s 163us/step - loss: 0.4327 - accuracy: 0.8677 - val_loss: 0.4829 - val_accuracy: 0.8493\n",
      "Epoch 48/100\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.4271 - accuracy: 0.8691 - val_loss: 0.4756 - val_accuracy: 0.8499\n",
      "Epoch 49/100\n",
      "36000/36000 [==============================] - 6s 158us/step - loss: 0.4215 - accuracy: 0.8689 - val_loss: 0.4747 - val_accuracy: 0.8495\n",
      "Epoch 50/100\n",
      "36000/36000 [==============================] - 6s 164us/step - loss: 0.4151 - accuracy: 0.8717 - val_loss: 0.4628 - val_accuracy: 0.8537\n",
      "Epoch 51/100\n",
      "36000/36000 [==============================] - 6s 162us/step - loss: 0.4056 - accuracy: 0.8740 - val_loss: 0.4588 - val_accuracy: 0.8539\n",
      "Epoch 52/100\n",
      "36000/36000 [==============================] - 6s 156us/step - loss: 0.4040 - accuracy: 0.8734 - val_loss: 0.4548 - val_accuracy: 0.8560\n",
      "Epoch 53/100\n",
      "36000/36000 [==============================] - 6s 164us/step - loss: 0.3976 - accuracy: 0.8742 - val_loss: 0.4564 - val_accuracy: 0.8536\n",
      "Epoch 54/100\n",
      "36000/36000 [==============================] - 6s 157us/step - loss: 0.3907 - accuracy: 0.8762 - val_loss: 0.4436 - val_accuracy: 0.8582\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.3864 - accuracy: 0.8781 - val_loss: 0.4427 - val_accuracy: 0.8568\n",
      "Epoch 56/100\n",
      "36000/36000 [==============================] - 6s 161us/step - loss: 0.3803 - accuracy: 0.8788 - val_loss: 0.4405 - val_accuracy: 0.8573\n",
      "Epoch 57/100\n",
      "36000/36000 [==============================] - 6s 155us/step - loss: 0.3756 - accuracy: 0.8807 - val_loss: 0.4398 - val_accuracy: 0.8574\n",
      "Epoch 58/100\n",
      "36000/36000 [==============================] - 6s 174us/step - loss: 0.3740 - accuracy: 0.8802 - val_loss: 0.4320 - val_accuracy: 0.8585\n",
      "Epoch 59/100\n",
      "36000/36000 [==============================] - 7s 181us/step - loss: 0.3700 - accuracy: 0.8809 - val_loss: 0.4281 - val_accuracy: 0.8616\n",
      "Epoch 60/100\n",
      "36000/36000 [==============================] - 6s 166us/step - loss: 0.3637 - accuracy: 0.8838 - val_loss: 0.4268 - val_accuracy: 0.8584\n",
      "Epoch 61/100\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.3645 - accuracy: 0.8819 - val_loss: 0.4235 - val_accuracy: 0.8623\n",
      "Epoch 62/100\n",
      "36000/36000 [==============================] - 6s 162us/step - loss: 0.3572 - accuracy: 0.8833 - val_loss: 0.4261 - val_accuracy: 0.8599\n",
      "Epoch 63/100\n",
      "36000/36000 [==============================] - 6s 176us/step - loss: 0.3544 - accuracy: 0.8844 - val_loss: 0.4202 - val_accuracy: 0.8607\n",
      "Epoch 64/100\n",
      "36000/36000 [==============================] - 6s 163us/step - loss: 0.3517 - accuracy: 0.8859 - val_loss: 0.4244 - val_accuracy: 0.8600\n",
      "Epoch 65/100\n",
      "36000/36000 [==============================] - 6s 169us/step - loss: 0.3503 - accuracy: 0.8854 - val_loss: 0.4164 - val_accuracy: 0.8622\n",
      "Epoch 66/100\n",
      "36000/36000 [==============================] - 6s 163us/step - loss: 0.3442 - accuracy: 0.8889 - val_loss: 0.4115 - val_accuracy: 0.8650\n",
      "Epoch 67/100\n",
      "36000/36000 [==============================] - 6s 166us/step - loss: 0.3419 - accuracy: 0.8878 - val_loss: 0.4129 - val_accuracy: 0.8630\n",
      "Epoch 68/100\n",
      "36000/36000 [==============================] - 6s 177us/step - loss: 0.3419 - accuracy: 0.8877 - val_loss: 0.4102 - val_accuracy: 0.8627\n",
      "Epoch 69/100\n",
      "36000/36000 [==============================] - 6s 169us/step - loss: 0.3384 - accuracy: 0.8878 - val_loss: 0.4037 - val_accuracy: 0.8662\n",
      "Epoch 70/100\n",
      "36000/36000 [==============================] - 6s 166us/step - loss: 0.3322 - accuracy: 0.8917 - val_loss: 0.4027 - val_accuracy: 0.8669\n",
      "Epoch 71/100\n",
      "36000/36000 [==============================] - 6s 169us/step - loss: 0.3304 - accuracy: 0.8923 - val_loss: 0.4040 - val_accuracy: 0.8663\n",
      "Epoch 72/100\n",
      "36000/36000 [==============================] - 6s 166us/step - loss: 0.3299 - accuracy: 0.8921 - val_loss: 0.4023 - val_accuracy: 0.8648\n",
      "Epoch 73/100\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.3258 - accuracy: 0.8932 - val_loss: 0.3991 - val_accuracy: 0.8665\n",
      "Epoch 74/100\n",
      "36000/36000 [==============================] - 6s 167us/step - loss: 0.3233 - accuracy: 0.8936 - val_loss: 0.4026 - val_accuracy: 0.8642\n",
      "Epoch 75/100\n",
      "36000/36000 [==============================] - 6s 165us/step - loss: 0.3233 - accuracy: 0.8931 - val_loss: 0.3971 - val_accuracy: 0.8668\n",
      "Epoch 76/100\n",
      "36000/36000 [==============================] - 6s 165us/step - loss: 0.3174 - accuracy: 0.8957 - val_loss: 0.4014 - val_accuracy: 0.8652\n",
      "Epoch 77/100\n",
      "36000/36000 [==============================] - 6s 170us/step - loss: 0.3193 - accuracy: 0.8945 - val_loss: 0.3960 - val_accuracy: 0.8664\n",
      "Epoch 78/100\n",
      "36000/36000 [==============================] - 6s 164us/step - loss: 0.3148 - accuracy: 0.8967 - val_loss: 0.3909 - val_accuracy: 0.8677\n",
      "Epoch 79/100\n",
      "36000/36000 [==============================] - 6s 164us/step - loss: 0.3146 - accuracy: 0.8957 - val_loss: 0.3903 - val_accuracy: 0.8698\n",
      "Epoch 80/100\n",
      "36000/36000 [==============================] - 6s 166us/step - loss: 0.3108 - accuracy: 0.8968 - val_loss: 0.3900 - val_accuracy: 0.8679\n",
      "Epoch 81/100\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.3069 - accuracy: 0.8983 - val_loss: 0.3937 - val_accuracy: 0.8673\n",
      "Epoch 82/100\n",
      "36000/36000 [==============================] - 6s 167us/step - loss: 0.3057 - accuracy: 0.8988 - val_loss: 0.3897 - val_accuracy: 0.8689\n",
      "Epoch 83/100\n",
      "36000/36000 [==============================] - 6s 162us/step - loss: 0.3045 - accuracy: 0.8989 - val_loss: 0.3918 - val_accuracy: 0.8670\n",
      "Epoch 84/100\n",
      "36000/36000 [==============================] - 6s 166us/step - loss: 0.3061 - accuracy: 0.8982 - val_loss: 0.3829 - val_accuracy: 0.8714\n",
      "Epoch 85/100\n",
      "36000/36000 [==============================] - 6s 159us/step - loss: 0.2986 - accuracy: 0.9014 - val_loss: 0.3899 - val_accuracy: 0.8663\n",
      "Epoch 86/100\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.3006 - accuracy: 0.9006 - val_loss: 0.3820 - val_accuracy: 0.8702\n",
      "Epoch 87/100\n",
      "36000/36000 [==============================] - 6s 168us/step - loss: 0.2965 - accuracy: 0.9024 - val_loss: 0.3866 - val_accuracy: 0.8699\n",
      "Epoch 88/100\n",
      "36000/36000 [==============================] - 6s 160us/step - loss: 0.2975 - accuracy: 0.9004 - val_loss: 0.3826 - val_accuracy: 0.8714\n",
      "Epoch 89/100\n",
      "36000/36000 [==============================] - 6s 155us/step - loss: 0.2943 - accuracy: 0.9026 - val_loss: 0.3791 - val_accuracy: 0.8714\n",
      "Epoch 90/100\n",
      "36000/36000 [==============================] - 6s 165us/step - loss: 0.2891 - accuracy: 0.9038 - val_loss: 0.3809 - val_accuracy: 0.8705\n",
      "Epoch 91/100\n",
      "36000/36000 [==============================] - 6s 159us/step - loss: 0.2915 - accuracy: 0.9029 - val_loss: 0.3759 - val_accuracy: 0.8717\n",
      "Epoch 92/100\n",
      "36000/36000 [==============================] - 6s 177us/step - loss: 0.2889 - accuracy: 0.9036 - val_loss: 0.3826 - val_accuracy: 0.8705\n",
      "Epoch 93/100\n",
      "36000/36000 [==============================] - 7s 184us/step - loss: 0.2894 - accuracy: 0.9036 - val_loss: 0.3815 - val_accuracy: 0.8702\n",
      "Epoch 94/100\n",
      "36000/36000 [==============================] - 7s 187us/step - loss: 0.2838 - accuracy: 0.9055 - val_loss: 0.3842 - val_accuracy: 0.8684\n",
      "Epoch 95/100\n",
      "36000/36000 [==============================] - 6s 165us/step - loss: 0.2832 - accuracy: 0.9059 - val_loss: 0.3771 - val_accuracy: 0.8694\n",
      "Epoch 96/100\n",
      "36000/36000 [==============================] - 6s 163us/step - loss: 0.2832 - accuracy: 0.9045 - val_loss: 0.3789 - val_accuracy: 0.8710\n",
      "Epoch 97/100\n",
      "36000/36000 [==============================] - 6s 168us/step - loss: 0.2836 - accuracy: 0.9052 - val_loss: 0.3752 - val_accuracy: 0.8706\n",
      "Epoch 98/100\n",
      "36000/36000 [==============================] - 6s 168us/step - loss: 0.2779 - accuracy: 0.9064 - val_loss: 0.3712 - val_accuracy: 0.8747\n",
      "Epoch 99/100\n",
      "36000/36000 [==============================] - 6s 159us/step - loss: 0.2769 - accuracy: 0.9073 - val_loss: 0.3742 - val_accuracy: 0.8722\n",
      "Epoch 100/100\n",
      "36000/36000 [==============================] - 6s 169us/step - loss: 0.2788 - accuracy: 0.9061 - val_loss: 0.3752 - val_accuracy: 0.8711\n"
     ]
    }
   ],
   "source": [
    "hist_ort = model_o.fit(train_input.values, train_label, epochs = 100, batch_size = 8192, validation_split = 0.4, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_k = keras.models.Sequential()\n",
    "model_k.add(Dense(units=1024, input_dim=train_input.shape[1], activation=\"relu\"))\n",
    "#model.add(Dropout(0.30))\n",
    "model_k.add(Dense(units=200, activation=\"relu\", kernel_initializer='he_uniform'))\n",
    "#model.add(Dropout(0.25))\n",
    "model_k.add(Dense(units=20, activation=\"relu\", kernel_initializer='he_uniform'))\n",
    "#model.add(Dropout(0.20))\n",
    "model_k.add(Dense(units=20, activation=\"relu\", kernel_initializer='he_uniform'))\n",
    "#model.add(Dropout(0.15))\n",
    "model_k.add(Dense(units=20, activation=\"relu\", kernel_initializer='he_uniform'))\n",
    "#model.add(Dropout(0.10))\n",
    "model_k.add(Dense(units=10, activation=\"softmax\", kernel_initializer='he_uniform'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_prop = RMSprop(lr=0.0001)\n",
    "model_k.compile(loss='categorical_crossentropy', \n",
    "              optimizer = rms_prop,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36000 samples, validate on 24000 samples\n",
      "Epoch 1/100\n",
      "36000/36000 [==============================] - 7s 194us/step - loss: 2.1547 - accuracy: 0.2324 - val_loss: 1.8009 - val_accuracy: 0.3659\n",
      "Epoch 2/100\n",
      "36000/36000 [==============================] - 7s 199us/step - loss: 1.7091 - accuracy: 0.3918 - val_loss: 1.5620 - val_accuracy: 0.4370\n",
      "Epoch 3/100\n",
      "36000/36000 [==============================] - 7s 184us/step - loss: 1.4863 - accuracy: 0.4686 - val_loss: 1.3807 - val_accuracy: 0.5236\n",
      "Epoch 4/100\n",
      "36000/36000 [==============================] - 6s 171us/step - loss: 1.3274 - accuracy: 0.5487 - val_loss: 1.2704 - val_accuracy: 0.5765\n",
      "Epoch 5/100\n",
      "36000/36000 [==============================] - 7s 183us/step - loss: 1.2154 - accuracy: 0.5987 - val_loss: 1.1700 - val_accuracy: 0.6156\n",
      "Epoch 6/100\n",
      "36000/36000 [==============================] - 7s 195us/step - loss: 1.1224 - accuracy: 0.6340 - val_loss: 1.0851 - val_accuracy: 0.6593\n",
      "Epoch 7/100\n",
      "36000/36000 [==============================] - 7s 201us/step - loss: 1.0330 - accuracy: 0.6738 - val_loss: 1.0167 - val_accuracy: 0.6796\n",
      "Epoch 8/100\n"
     ]
    }
   ],
   "source": [
    "hist_kam = model_k.fit(train_input.values, train_label, epochs = 100, batch_size = 8192, validation_split = 0.4, shuffle = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
